---
title: "Replication of Study 3 in Artful Paltering: The Risks and Rewards of Using Truthful Statements to Mislead Others by Rogers, Zeckhauser, Gino, Norton, & Schweitzer (2017, Journal of Personality and Social Psychology)"
author: "Kayla Good (kagood@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

### Links

Github Project Repository: https://github.com/psych251/rogers2017

Original paper: https://github.com/psych251/rogers2017/blob/master/original_paper/Rogers_et_al_2017.pdf

### Justification

In my research, I am primarily interested in exploring how different linguistic devices and forms of conversational implicature influence children's and adults' interpretations and evaluations of messages in a variety of domains, including the domains of achievement, preventative health, and nutrition. Recently, I developed a specific interest in how adults and children evaluate paltering, or the act of making statements that, while technically true, lead others to draw false conclusions. In the present replication project, I will replicate Study 3 of Rogers et al. (2017), which aimed to compare adults' evaluations of the ethicality of paltering with their evaluations of honesty and another form of deception (lying by commission, or making false statements). 

### Study Description

In Study 3, Rogers et al. (2017) asked adults to imagine that they were engaged in a negotiation and that their negotiation partner had either been honest, paltered, or lied by commission. I aim to replicate the finding that adults evaluate partners who palter or lie by commission as equally unethical and untrustworthy (compared to honest partners) and report an equally low likelihood of entering into a subsequent negotiation with either partner (again, compared to honest partners, for whom they report a higher likelihood of agreeing to another negotiation).

### Planned Stimuli 

The original study was carried out with 160 participants (who were paid $0.50 each) on Amazon Mechanical Turk. Participants will be recruited in the same manner with a sample size calculated via a power analysis. Only adults (ages 18 and older) living in the United States will be eligible to participate.

### Planned Procedure

As in the original study, participants will be directed to a Qualtrics survey in which they will be presented with a written scenario to read and consider. This scenario, which will comprise most of the stimuli necessary for this experiment, will ask participants to imagine that they have to sell a large piece of real estate property, which will vary in value depending on whether the buyer intends to develop it for commercial or residential purposes. They will then be told that they will be negotiating with a potential buyer. Participants will then be randomly assigned to one of three conditions, in which the buyer is either honest about their intention for the property, palters, or lies by commission. After learning that the buyer was either honest or deceptive, participants will then be asked to provide ratings (on 7-point Likert scales) of the buyer's ethicality as well as their trust in the buyer and their likelihood of engaging in another negotiation with the buyer. The survey will contain an attention check item prior to condition assignment to ensure that participants who are inattentive are excluded (per the procedure used in the original study).

### Challenges

Because I am relatively new to R and Github, I think that one of the primary challenges will involve my gaining the required knowledge and skills necessary for handling data and carrying out data analyses. However, I am confident that, with the skills we are learning in class as well as my having a strong background in STATA (and perhaps more importantly, experience with using Google to troubleshoot issues in STATA), I think this will be an appropriately difficult challenge. From a data collection standpoint, I think it will be challenging to ensure that the sample size is not affected substantially by exclusions due to failed attention checks; however, by being thoughtful about survey design and crafting a clear MTurk HIT description, I think that this issue can be minimized. Finally, I think it might be a slight challenge to stay within budget, given the relatively high compensation rate used in the original study. However, I am going to try my best to use the same payment ($0.50 per participant) in order to maintain as much consistency with the original study as possible. 

## Methods

### Power Analysis

Original effect size, power analysis for samples to achieve 80%, 90%, 95% power to detect that effect size.  Considerations of feasibility for selecting planned sample size.

### Planned Sample

Planned sample size and/or termination rule, sampling frame, known demographics if any, preselection rules if any.

### Materials

All materials - can quote directly from original article - just put the text in quotations and note that this was followed precisely.  Or, quote directly and just point out exceptions to what was described in the original article.

### Procedure	

Can quote directly from original article - just put the text in quotations and note that this was followed precisely.  Or, quote directly and just point out exceptions to what was described in the original article.

### Analysis Plan

Can also quote directly, though it is less often spelled out effectively for an analysis strategy section.  The key is to report an analysis strategy that is as close to the original - data cleaning rules, data exclusion rules, covariates, etc. - as possible.  

**Clarify key analysis of interest here**  You can also pre-specify additional analyses you plan to do.

### Differences from Original Study

Explicitly describe known differences in sample, setting, procedure, and analysis plan from original study.  The goal, of course, is to minimize those differences, but differences will inevitably occur.  Also, note whether such differences are anticipated to make a difference based on claims in the original article or subsequent published research on the conditions for obtaining the effect.

### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.

#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.


##Results


### Data preparation

Data preparation following the analysis plan.
	
```{r include=F}
###Data Preparation

####Load Relevant Libraries and Functions

####Import data

#### Data exclusion / filtering

#### Prepare data for analysis - create columns etc.
```

### Confirmatory analysis

The analyses as specified in the analysis plan.  

*Side-by-side graph with original graph is ideal here*

### Exploratory analyses

Any follow-up analyses desired (not required).  

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
